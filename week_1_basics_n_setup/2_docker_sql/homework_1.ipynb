{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f5130a-5c13-4d35-a27a-cdaed47f8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23ae08b-316b-4177-8760-fc93f35686d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "raw",
   "id": "238281ba-e26d-46f4-8afc-c925bda36bcc",
   "metadata": {},
   "source": [
    "\n",
    "engine = create_engine('postgresql://db_username:db_password@db_hostname:db_port/db_name')\n",
    "\n",
    "# specify db parameters before running this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e345eee-199a-4876-90d2-c8ff96d5b6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x20e52060e20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10e66c29-b664-4d15-abc9-b5de9132f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv('green_tripdata.csv', iterator=True, chunksize=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "451b6e2a-803c-452a-92d4-2f174d99deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60ee335f-c2c2-4540-84eb-a0b3fb09337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3232e96-7922-4a8f-b522-33bd1e014d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c40ef7-4d2b-4792-a48e-034cfe3a9ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE green_tripdata (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type BIGINT, \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name=\"green_tripdata\", con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e45dcf8-e43d-4384-a384-c9265605a394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(0).to_sql(name=\"green_tripdata\", con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dbfe936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ?column?\n",
       "0         1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT 1;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87f831d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65cc661f-acc0-4a87-863c-b3bd331c7b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 22.894 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 19.212 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 35.699 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 25.828 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 24.941 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 55.604 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 25.627 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 18.617 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 11.355 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 10.183 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 29.859 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 15.235 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 17.468 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 16.257 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 32.117 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 10.150 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 14.940 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 20.416 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 59.822 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 222.357 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 50.085 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 18.792 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 14.873 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 14.431 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.194 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.248 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 8.621 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.641 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.993 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.107 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 6.050 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.464 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 5.037 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 5.003 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.534 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 5.574 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.149 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 5.036 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.602 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.150 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 8.096 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 6.380 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 7.289 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 8.538 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 5.775 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 5.419 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 6.783 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 18.883 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 12.885 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 8.983 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 12.402 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 15.054 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 15.814 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 20.414 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 54.660 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 13.210 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 6.156 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 14.305 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 10.560 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 8.354 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 7.698 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 14.868 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 9.319 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 8.957 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 10.792 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 14.410 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 11.530 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 13.801 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 18.174 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 7.717 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 13.422 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.763 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.918 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.708 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 13.334 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 5.814 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 10.817 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 2.892 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 11.732 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.302 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 7.040 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.389 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.948 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 6.056 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 5.059 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.274 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.115 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.589 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 4.408 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 6.681 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 3.841 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 10.696 seconds\n",
      "Processing chunk with 5000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agyei\\AppData\\Local\\Temp\\ipykernel_11864\\3629730013.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk, took 10.086 seconds\n",
      "Processing chunk with 5000 rows\n",
      "Inserted another chunk, took 9.140 seconds\n",
      "Processing chunk with 1386 rows\n",
      "Inserted another chunk, took 2.078 seconds\n",
      "All chunks have been processed. Total rows inserted: {total_rows_processed}\n"
     ]
    }
   ],
   "source": [
    "total_rows_processed = 0\n",
    "while True:\n",
    "    try:\n",
    "        t_start = time()\n",
    "\n",
    "        df = next(df_iter)\n",
    "        print(f\"Processing chunk with {len(df)} rows\")\n",
    "\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "\n",
    "        df.to_sql(name='green_tripdata', con=engine, if_exists='append')\n",
    "\n",
    "        total_rows_processed += len(df)\n",
    "        t_end = time()\n",
    "        print(f'Inserted another chunk, took {t_end - t_start:.3f} seconds')\n",
    "\n",
    "    except StopIteration:\n",
    "   \n",
    "        print(\"All chunks have been processed. Total rows inserted: {total_rows_processed}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdc11b29-0838-4e1e-950d-eb3865526cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"taxi_zone.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf710566-47bb-4a8b-aaac-c73d1c871579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE taxi_zone (\n",
      "\t\"LocationID\" BIGINT, \n",
      "\t\"Borough\" TEXT, \n",
      "\t\"Zone\" TEXT, \n",
      "\tservice_zone TEXT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df_1, name=\"taxi_zone\", con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24502a8e-0947-4d4b-ac3a-325afd48961d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [LocationID, Borough, Zone, service_zone]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1304f8b6-07cf-4db8-819a-63a974bc84f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(0).to_sql(name=\"taxi_zone\", con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d3bf7bb-d3fa-40ef-8ccc-e3e89cc0de3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.to_sql(name='taxi_zone', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6e795b3-0082-407b-9a8d-f30224a39d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_a</th>\n",
       "      <th>count_b</th>\n",
       "      <th>count_c</th>\n",
       "      <th>count_d</th>\n",
       "      <th>count_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103486</td>\n",
       "      <td>196663</td>\n",
       "      <td>108704</td>\n",
       "      <td>27459</td>\n",
       "      <td>35044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_a  count_b  count_c  count_d  count_e\n",
       "0   103486   196663   108704    27459    35044"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_q3 = \"\"\"\n",
    "SELECT  \n",
    "  COUNT(CASE WHEN trip_distance <= 1 THEN 1 END) AS count_a,\n",
    "  COUNT(CASE WHEN trip_distance > 1 AND trip_distance <= 3 THEN 1 END) AS count_b,\n",
    "  COUNT(CASE WHEN trip_distance > 3 AND trip_distance <= 7 THEN 1 END) AS count_c,\n",
    "  COUNT(CASE WHEN trip_distance > 7 AND trip_distance <= 10 THEN 1 END) AS count_d,\n",
    "  COUNT(CASE WHEN trip_distance > 10 THEN 1 END) AS count_e\n",
    "FROM \n",
    "  green_tripdata\n",
    "WHERE \n",
    "  lpep_pickup_datetime >= '2019-10-01' \n",
    "  AND lpep_pickup_datetime < '2019-11-01';\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query_q3, con=engine)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e37116d9-5c24-4d9e-84fd-d22d4e3dd52f",
   "metadata": {},
   "source": [
    "I noted that the final chunk for green_tripdata is also not ingested\n",
    "Hence my final answer for Q.3 is inaccurate\n",
    "Hower, I believe strong that my query is accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c5bfeff-6fc3-4041-aaae-5d3b7dbb8d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-31 23:23:41</td>\n",
       "      <td>515.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lpep_pickup_datetime  trip_distance\n",
       "0  2019-10-31 23:23:41         515.89"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_q4 = \"\"\"\n",
    "SELECT\n",
    "  lpep_pickup_datetime,\n",
    "  trip_distance\n",
    "FROM \n",
    "  green_tripdata\n",
    "ORDER BY\n",
    "  trip_distance DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query_q4, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89066bbc-fd14-4370-8e2d-a1ba5127fa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>pickup_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>18686.68</td>\n",
       "      <td>East Harlem North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>16797.26</td>\n",
       "      <td>East Harlem South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>13029.79</td>\n",
       "      <td>Morningside Heights</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID  total_amount          pickup_zone\n",
       "0            74      18686.68    East Harlem North\n",
       "1            75      16797.26    East Harlem South\n",
       "2           166      13029.79  Morningside Heights"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_q5 = \"\"\"\n",
    "SELECT \n",
    "    t.\"PULocationID\", \n",
    "    SUM(total_amount) AS total_amount,\n",
    "\tz.\"Zone\" AS pickup_zone\n",
    "FROM \n",
    "    green_tripdata t\n",
    "JOIN taxi_zone z \n",
    "    ON t.\"PULocationID\" = z.\"LocationID\"\n",
    "WHERE \n",
    "    DATE(lpep_pickup_datetime) = '2019-10-18'\n",
    "GROUP BY \n",
    "    t.\"PULocationID\", z.\"Zone\"\n",
    "HAVING \n",
    "    SUM(total_amount) > 13000\n",
    "ORDER BY \n",
    "    total_amount DESC;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query_q5, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "115161fc-5a2b-48c5-b469-f7b3c646369c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_year</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>largest_tip</th>\n",
       "      <th>dropoff_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10</td>\n",
       "      <td>74</td>\n",
       "      <td>87.3</td>\n",
       "      <td>JFK Airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_year  PULocationID  largest_tip  dropoff_loc\n",
       "0    2019-10            74         87.3  JFK Airport"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_q6 = \"\"\"\n",
    "SELECT\n",
    "  TO_CHAR(lpep_pickup_datetime, 'YYYY-MM') AS month_year,\n",
    "  \"PULocationID\",\n",
    "  tip_amount AS largest_tip,\n",
    "  z.\"Zone\" AS \"dropoff_loc\"\n",
    "FROM \n",
    "    green_tripdata t\n",
    "JOIN taxi_zone z \n",
    "    ON t.\"DOLocationID\" = z.\"LocationID\"\n",
    "WHERE\n",
    "\tTO_CHAR(lpep_pickup_datetime, 'YYYY-MM') = '2019-10'\n",
    "\tAND \"PULocationID\" = (\n",
    "        SELECT \"LocationID\"\n",
    "        FROM taxi_zone\n",
    "        WHERE \"Zone\" = 'East Harlem North')\n",
    "ORDER BY \n",
    "    largest_tip DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query_q6, con=engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
